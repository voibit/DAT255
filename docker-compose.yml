services:
  fastai:
    image: voidbit/ml
    build: docker
    ports:
      - "80:80" # Jupyterlab
      - "6006:6006" # TENSORBOARD
      - "8088:8088" # REST CLIENT
    volumes:
      - ./:/app/local
      - ./.fastai/:/home/user/.fastai
    command: "run_jupyterlab.sh"
    <<: &gpustuff
      ipc: host
      deploy:
        resources:
          reservations:
            devices:
              - capabilities: [gpu]

  rest:
    image: voidbit/ml
    #build: docker
    ports:
      - "8088:8088" # REST CLIENT
    volumes:
      - ./:/app/local
      - ./.fastai/:/home/user/.fastai
    command: "-c \"python /app/local/DeepShip/rest.py\""
    <<: *gpustuff

  tf:
    image: jk/tf
    build:
      context: docker
      dockerfile: Dockerfile.tf
    ports:
      - "6006:6006" # TENSORBOARD
      - "80:80" # Jupyterlab
    volumes:
      - ./:/tf/local
    command: "run_jupyterlab.sh"
    <<: *gpustuff


